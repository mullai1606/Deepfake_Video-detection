{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import cv2\n",
    "import math\n",
    "import fnmatch\n",
    "import imutils\n",
    "from google.colab.patches import cv2_imshow\n",
    "from decimal import Decimal\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "import PIL\n",
    "from PIL import Image\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip uninstall h5py\n",
    "!pip install h5py==3.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/') #by default gdrive path will be /content/drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!sudo add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!sudo apt-get update -qq 2>&1 > /dev/null\n",
    "!sudo apt -y install -qq google-drive-ocamlfuse 2>&1 > /dev/null\n",
    "!google-drive-ocamlfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install -qq w3m # to act as web browser\n",
    "!xdg-settings set default-web-browser w3m.desktop # to set default browser\n",
    "%cd /content\n",
    "!mkdir drive2\n",
    "%cd drive2\n",
    "!mkdir MyDrive\n",
    "%cd ..\n",
    "%cd ..\n",
    "!google-drive-ocamlfuse /content/drive2/MyDrive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TestCases : Real Single Face Video , Real Multiple faces , Fake Single face Video, Multiple face fake video \n",
    "use these bellow code cells for the testcases as a template by changing the actual class and input path  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "inputvidpath='Give the path of the input video \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "actualclass='real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "vidname= inputvidpath.split(\"/\")[5]\n",
    "print(vidname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mp4 = open(inputvidpath,'rb').read()   #rb-reading a binary file like an image file and not a text file\n",
    "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=400 controls>\n",
    "      <source src=\"%s\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\" % data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "path=\"/content/drive/MyDrive/sample-images/\"+vidname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Frame split-up module\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "def getFrame(sec):\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,image = vidcap.read()\n",
    "    if hasFrames:\n",
    "        cv2.imwrite(\"image\"+str(count)+\".jpg\", image) # save frame as JPG file in the current directory\n",
    "        #plt.imshow(image)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #plt.imshow(image)\n",
    "    return hasFrames\n",
    "\n",
    "\n",
    "vidcap = cv2.VideoCapture(inputvidpath)\n",
    "sec = 0\n",
    "frameRate = 0.10 #10 frames per second\n",
    "count=1\n",
    "vidname= inputvidpath.split(\"/\")[5]\n",
    "path=\"/content/drive/MyDrive/sample-images/\"+vidname\n",
    "if os.path.exists(path):\n",
    "   shutil.rmtree(path, ignore_errors=True); #if path already exists delete it\n",
    "os.makedirs(path);\n",
    "os.chdir(path)#change the current directory to the path\n",
    "success = getFrame(sec)\n",
    "while success:\n",
    "    count = count + 1\n",
    "    sec = sec + frameRate\n",
    "    sec = round(sec, 2)\n",
    "    success = getFrame(sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "l=len(os.listdir(path))\n",
    "print(l)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Finding keyframes for extracted frames\n",
    "diff=[]\n",
    "imageA = cv2.imread( path+'/image'+str(1)+'.jpg')\n",
    "grayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\n",
    "diff.append(cv2.absdiff(grayA, grayA))\n",
    "for i in range(1,l):#loops till l-1. For 7 images 6 comparisons are needed\n",
    "  imageA = cv2.imread( path+'/image'+str(i)+'.jpg')\n",
    "  imageB = cv2.imread(path+'/image'+str(i+1)+'.jpg')\n",
    "  #print(i,\":::\",imageA.shape)\n",
    "  #print(i+1,\":::\",imageB.shape)\n",
    "  grayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\n",
    "  grayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n",
    "  diff.append(cv2.absdiff(grayA, grayB))\n",
    " #print(diff)\n",
    "mn = np.mean(diff)\n",
    "st_d = np.std(diff)\n",
    " #print(mn,st_d)\n",
    "a = 4\n",
    "ts = mn + (a * st_d)\n",
    " #print('The threshold==>',ts)\n",
    "print(\"length of diff array:\",len(diff))\n",
    "a_fr = []#Creating an empty list\n",
    "for i in range(len(diff)):\n",
    "    mn = np.mean(diff[i])#Calculating the mean for each frame\n",
    "    st_d = np.std(diff[i])\n",
    "    fr_ts = mn + (4*st_d)#Finding the threshold values for each frame/image\n",
    "    #print(i,fr_ts)\n",
    "    a_fr.append([i,fr_ts])\n",
    "keyframes = []\n",
    "for i,ac_tr in(a_fr):\n",
    "    if ac_tr >= ts:\n",
    "        #print(i,ac_tr)\n",
    "        keyframes.append(i)\n",
    "print(keyframes)\n",
    "print(\"Length:\",len(keyframes))\n",
    " #Renaming\n",
    "x=len(fnmatch.filter(os.listdir(path), 'key*.jpg'))\n",
    "if(x==0):   #if no keyframe has been previously created, create keyframes\n",
    "  for i in range(0,len(keyframes)):\n",
    "   oldname=path+\"/image\"+str(keyframes[i])+\".jpg\"\n",
    "   newname=path+\"/key\"+str(i+1)+\".jpg\"\n",
    "   os.rename(oldname, newname)\n",
    "#Check\n",
    "print(\"check:\", len(fnmatch.filter(os.listdir(path), 'key*.jpg'))    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#To remove un-necessary frames after finding keyframes\n",
    "import glob\n",
    "#Add proper file path\n",
    "removefilelist=glob.glob(path+\"/**/image*.jpg\", recursive=True) # all imgs(not keyframes) from all videos\n",
    "for filePath in removefilelist:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "        #print(filePath)\n",
    "    except OSError:\n",
    "        print(\"Error while deleting file\",filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "cols=5\n",
    "rows=math.ceil(len(keyframes)/cols)\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16,10))\n",
    "cols=5\n",
    "rows=math.ceil(len(keyframes)/cols)\n",
    "for j in range(0,rows*cols):\n",
    " fig.add_subplot(rows,cols,j+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(16,10))\n",
    "cols=5\n",
    "rows=math.ceil(len(keyframes)/cols)\n",
    "for j in range(0,len(keyframes)):\n",
    " fig.add_subplot(rows,cols,j+1)\n",
    " img=cv2.imread(path+\"/key\"+str(j+1)+\".jpg\")\n",
    " img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    " plt.imshow(img)\n",
    " plt.title(\"keyFrame\"+str(j+1))\n",
    " plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "from tensorflow.python.keras.layers import Conv2D, Input, ZeroPadding2D, Dense, Lambda\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def load_mobilenetv2_224_075_detector(path):\n",
    "\n",
    "\n",
    "  input_tensor = tf.keras.Input(shape=(224, 224, 3))\n",
    "  output_tensor = MobileNetV2(weights=None, include_top=False, input_tensor=input_tensor, alpha=0.75).output\n",
    "  output_tensor = tf.keras.layers.ZeroPadding2D()(output_tensor)\n",
    "  output_tensor = tf.keras.layers.Conv2D(kernel_size=(3, 3), filters=5)(output_tensor)\n",
    "\n",
    "  model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "  try:\n",
    "    model.load_weights(path)\n",
    "  except ValueError as e:\n",
    "    # If the model architecture does not match the weight file architecture,\n",
    "    # update the model architecture to match the weight file architecture.\n",
    "\n",
    "    if 'You are trying to load a weight file containing 106 layers into a model with 1 layers.' in e:\n",
    "      model.compile(optimizer='adam')\n",
    "\n",
    "  return model\n",
    "\n",
    "mobilenetv2 = load_mobilenetv2_224_075_detector(\"/content/drive/MyDrive/deepfake/facedetection-mobilenetv2-size224-alpha0.75.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Converts A:B aspect rate to B:A\n",
    "def transpose_shots(shots):\n",
    "    return [(shot[1], shot[0], shot[3], shot[2], shot[4]) for shot in shots]\n",
    "\n",
    "#That constant describe pieces for 16:9 images\n",
    "SHOTS = {\n",
    "    # fast less accurate\n",
    "    '2-16/9' : {\n",
    "        'aspect_ratio' : 16/9,\n",
    "        'shots' : [\n",
    "             (0, 0, 9/16, 1, 1),\n",
    "             (7/16, 0, 9/16, 1, 1)\n",
    "        ]\n",
    "    },\n",
    "    # slower more accurate\n",
    "    '10-16/9' : {\n",
    "        'aspect_ratio' : 16/9,\n",
    "        'shots' : [\n",
    "             (0, 0, 9/16, 1, 1),\n",
    "             (7/16, 0, 9/16, 1, 1),\n",
    "             (0, 0, 5/16, 5/9, 0.5),\n",
    "             (0, 4/9, 5/16, 5/9, 0.5),\n",
    "             (11/48, 0, 5/16, 5/9, 0.5),\n",
    "             (11/48, 4/9, 5/16, 5/9, 0.5),\n",
    "             (22/48, 0, 5/16, 5/9, 0.5),\n",
    "             (22/48, 4/9, 5/16, 5/9, 0.5),\n",
    "             (11/16, 0, 5/16, 5/9, 0.5),\n",
    "             (11/16, 4/9, 5/16, 5/9, 0.5),\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# 9:16 respectively\n",
    "SHOTS_T = {\n",
    "    '2-9/16' : {\n",
    "        'aspect_ratio' : 9/16,\n",
    "        'shots' : transpose_shots(SHOTS['2-16/9']['shots'])\n",
    "    },\n",
    "    '10-9/16' : {\n",
    "        'aspect_ratio' : 9/16,\n",
    "        'shots' : transpose_shots(SHOTS['10-16/9']['shots'])\n",
    "    }\n",
    "}\n",
    "\n",
    "def r(x):\n",
    "    return int(round(x))\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (np.exp(-x) + 1)\n",
    "\n",
    "def non_max_suppression(boxes, p, iou_threshold):\n",
    "\n",
    "    if len(boxes) == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    indexes = np.argsort(p)\n",
    "    true_boxes_indexes = []\n",
    "\n",
    "    while len(indexes) > 0:\n",
    "        true_boxes_indexes.append(indexes[-1])\n",
    "\n",
    "        intersection = np.maximum(np.minimum(x2[indexes[:-1]], x2[indexes[-1]]) - np.maximum(x1[indexes[:-1]], x1[indexes[-1]]), 0) * np.maximum(np.minimum(y2[indexes[:-1]], y2[indexes[-1]]) - np.maximum(y1[indexes[:-1]], y1[indexes[-1]]), 0)\n",
    "        iou = intersection / ((x2[indexes[:-1]] - x1[indexes[:-1]]) * (y2[indexes[:-1]] - y1[indexes[:-1]]) + (x2[indexes[-1]] - x1[indexes[-1]]) * (y2[indexes[-1]] - y1[indexes[-1]]) - intersection)\n",
    "\n",
    "        indexes = np.delete(indexes, -1)\n",
    "        indexes = np.delete(indexes, np.where(iou >= iou_threshold)[0])\n",
    "\n",
    "    return boxes[true_boxes_indexes]\n",
    "\n",
    "def union_suppression(boxes, threshold):\n",
    "    if len(boxes) == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    indexes = np.argsort((x2 - x1) * (y2 - y1))\n",
    "    result_boxes = []\n",
    "\n",
    "    while len(indexes) > 0:\n",
    "        intersection = np.maximum(np.minimum(x2[indexes[:-1]], x2[indexes[-1]]) - np.maximum(x1[indexes[:-1]], x1[indexes[-1]]), 0) * np.maximum(np.minimum(y2[indexes[:-1]], y2[indexes[-1]]) - np.maximum(y1[indexes[:-1]], y1[indexes[-1]]), 0)\n",
    "        min_s = np.minimum((x2[indexes[:-1]] - x1[indexes[:-1]]) * (y2[indexes[:-1]] - y1[indexes[:-1]]), (x2[indexes[-1]] - x1[indexes[-1]]) * (y2[indexes[-1]] - y1[indexes[-1]]))\n",
    "        ioms = intersection / (min_s + 1e-9)\n",
    "        neighbours = np.where(ioms >= threshold)[0]\n",
    "        if len(neighbours) > 0:\n",
    "            result_boxes.append([min(np.min(x1[indexes[neighbours]]), x1[indexes[-1]]), min(np.min(y1[indexes[neighbours]]), y1[indexes[-1]]), max(np.max(x2[indexes[neighbours]]), x2[indexes[-1]]), max(np.max(y2[indexes[neighbours]]), y2[indexes[-1]])])\n",
    "        else:\n",
    "            result_boxes.append([x1[indexes[-1]], y1[indexes[-1]], x2[indexes[-1]], y2[indexes[-1]]])\n",
    "\n",
    "        indexes = np.delete(indexes, -1)\n",
    "        indexes = np.delete(indexes, neighbours)\n",
    "\n",
    "    return result_boxes\n",
    "\n",
    "class FaceDetector():\n",
    "\n",
    "    def __init__(self, model=mobilenetv2, shots=[SHOTS['10-16/9'], SHOTS_T['10-9/16']], image_size=224, grids=7, iou_threshold=0.1, union_threshold=0.1, prob_threshold=0.65):\n",
    "        self.model = model\n",
    "        self.shots = shots\n",
    "        self.image_size = image_size\n",
    "        self.grids = grids\n",
    "        self.iou_threshold = iou_threshold\n",
    "        self.union_threshold = union_threshold\n",
    "        self.prob_threshold = prob_threshold\n",
    "\n",
    "\n",
    "    def detect(self, frame):\n",
    "        original_frame_shape = frame.shape\n",
    "\n",
    "        aspect_ratio = None\n",
    "        for shot in self.shots:\n",
    "            if abs(frame.shape[1] / frame.shape[0] - shot[\"aspect_ratio\"]) < 1e-9:\n",
    "                aspect_ratio = shot[\"aspect_ratio\"]\n",
    "                shots = shot\n",
    "\n",
    "        assert aspect_ratio is not None\n",
    "\n",
    "        c = min(frame.shape[0], frame.shape[1] / aspect_ratio)\n",
    "        slice_h_shift = r((frame.shape[0] - c) / 2)\n",
    "        slice_w_shift = r((frame.shape[1] - c * aspect_ratio) / 2)\n",
    "        if slice_w_shift != 0 and slice_h_shift == 0:\n",
    "            frame = frame[:, slice_w_shift:-slice_w_shift]\n",
    "        elif slice_w_shift == 0 and slice_h_shift != 0:\n",
    "            frame = frame[slice_h_shift:-slice_h_shift, :]\n",
    "\n",
    "        frames = []\n",
    "        for s in shots[\"shots\"]:\n",
    "            frames.append(cv2.resize(frame[r(s[1] * frame.shape[0]):r((s[1] + s[3]) * frame.shape[0]), r(s[0] * frame.shape[1]):r((s[0] + s[2]) * frame.shape[1])], (self.image_size, self.image_size), interpolation=cv2.INTER_NEAREST))\n",
    "        frames = np.array(frames)\n",
    "\n",
    "        predictions = self.model.predict(frames, batch_size=len(frames), verbose=0)\n",
    "        predictions.shape\n",
    "\n",
    "\n",
    "        boxes = []\n",
    "        prob = []\n",
    "        shots = shots['shots']\n",
    "        for i in range(len(shots)):\n",
    "            slice_boxes = []\n",
    "            slice_prob = []\n",
    "            for j in range(predictions.shape[1]):\n",
    "              if len(predictions.shape) > 2:\n",
    "                for k in range(predictions.shape[2]):\n",
    "\n",
    "\n",
    "\n",
    "                    p = sigmoid(predictions[i][j][k][4])\n",
    "                    if not(p is None) and p > self.prob_threshold:\n",
    "                        px = sigmoid(predictions[i][j][k][0])\n",
    "                        py = sigmoid(predictions[i][j][k][1])\n",
    "                        pw = min(math.exp(predictions[i][j][k][2] / self.grids), self.grids)\n",
    "                        ph = min(math.exp(predictions[i][j][k][3] / self.grids), self.grids)\n",
    "                        if not(px is None) and not(py is None) and not(pw is None) and not(ph is None) and pw > 1e-9 and ph > 1e-9:\n",
    "                            cx = (px + j) / self.grids\n",
    "                            cy = (py + k) / self.grids\n",
    "                            wx = pw / self.grids\n",
    "                            wy = ph / self.grids\n",
    "                            if wx <= shots[i][4] and wy <= shots[i][4]:\n",
    "                                lx = min(max(cx - wx / 2, 0), 1)\n",
    "                                ly = min(max(cy - wy / 2, 0), 1)\n",
    "                                rx = min(max(cx + wx / 2, 0), 1)\n",
    "                                ry = min(max(cy + wy / 2, 0), 1)\n",
    "\n",
    "                                lx *= shots[i][2]\n",
    "                                ly *= shots[i][3]\n",
    "                                rx *= shots[i][2]\n",
    "                                ry *= shots[i][3]\n",
    "\n",
    "                                lx += shots[i][0]\n",
    "                                ly += shots[i][1]\n",
    "                                rx += shots[i][0]\n",
    "                                ry += shots[i][1]\n",
    "\n",
    "                                slice_boxes.append([lx, ly, rx, ry])\n",
    "                                slice_prob.append(p)\n",
    "\n",
    "            slice_boxes = np.array(slice_boxes)\n",
    "            slice_prob = np.array(slice_prob)\n",
    "\n",
    "            slice_boxes = non_max_suppression(slice_boxes, slice_prob, self.iou_threshold)\n",
    "\n",
    "            for sb in slice_boxes:\n",
    "                boxes.append(sb)\n",
    "\n",
    "\n",
    "        boxes = np.array(boxes)\n",
    "        boxes = union_suppression(boxes, self.union_threshold)\n",
    "\n",
    "        for i in range(len(boxes)):\n",
    "            boxes[i][0] /= original_frame_shape[1] / frame.shape[1]\n",
    "            boxes[i][1] /= original_frame_shape[0] / frame.shape[0]\n",
    "            boxes[i][2] /= original_frame_shape[1] / frame.shape[1]\n",
    "            boxes[i][3] /= original_frame_shape[0] / frame.shape[0]\n",
    "\n",
    "            boxes[i][0] += slice_w_shift / original_frame_shape[1]\n",
    "            boxes[i][1] += slice_h_shift / original_frame_shape[0]\n",
    "            boxes[i][2] += slice_w_shift / original_frame_shape[1]\n",
    "            boxes[i][3] += slice_h_shift / original_frame_shape[0]\n",
    "\n",
    "        return list(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def setaspectratio( filepath ):\n",
    "  from PIL import Image\n",
    "  from numpy import size\n",
    "  from numpy import asarray\n",
    "  image  = Image.open(filepath )\n",
    "  #image= cv2.imread(ff_image_path+\"/\"+imgvid[3]+\"/key2.jpg\")\n",
    "  width  = image.size[0]\n",
    "  height = image.size[1]\n",
    "  #print(width,height)\n",
    "  aspect = width / float(height)\n",
    "\n",
    "  ideal_width = 1280\n",
    "  ideal_height = 720\n",
    "  if(width != ideal_width or height!= ideal_height):\n",
    "   ideal_aspect = ideal_width / float(ideal_height)\n",
    "\n",
    "   if aspect > ideal_aspect:\n",
    "    # Then crop the left and right edges:\n",
    "    new_width = int(ideal_aspect * height)\n",
    "    offset = (width - new_width) / 2\n",
    "    resize = (offset, 0, width - offset, height)\n",
    "   else:\n",
    "    # ... crop the top and bottom:\n",
    "    new_height = int(width / ideal_aspect)\n",
    "    offset = (height - new_height) / 2\n",
    "    resize = (0, offset, width, height - offset)\n",
    "\n",
    "   thu = image.crop(resize)\n",
    "   thu=thu.resize((ideal_width, ideal_height), Image.Resampling.LANCZOS)\n",
    "   #model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "\n",
    "   ffff= asarray(thu)\n",
    "   return ffff\n",
    "  else:\n",
    "   ffff= asarray(image)\n",
    "   return ffff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "detector = FaceDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "detector = FaceDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# A sample face detection image\n",
    "#frame=cv2.imread(path+\"/key1.jpg\")\n",
    "#frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "frame=setaspectratio(path+\"/key1.jpg\")\n",
    "rgbframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(frame)\n",
    "dim=(299,299)\n",
    "boxes = detector.detect(frame)\n",
    " # lets's draw boxes, just multiply each predicted [0, 1] relative coordinate to image side in pixels respectively\n",
    "for box in boxes:\n",
    "        lx = int(round(box[0] * frame.shape[1]))\n",
    "        ly = int(round(box[1] * frame.shape[0]))\n",
    "        rx = int(round(box[2] * frame.shape[1]))\n",
    "        ry = int(round(box[3] * frame.shape[0]))\n",
    "        # x, y, w, h here\n",
    "        ax.add_patch(Rectangle((lx,ly),rx - lx,ry - ly,linewidth=2,edgecolor='r',facecolor='none'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Face extraction and storage\n",
    "\n",
    "#dim=(w,h)\n",
    "dim=(299,299)\n",
    "b=1\n",
    "storagepath=\"/content/drive/MyDrive/sample-faces/\"+vidname   #path to store extracted faces\n",
    "if os.path.exists(storagepath):\n",
    "   shutil.rmtree(storagepath, ignore_errors=True); #if path already exists delete it\n",
    "os.makedirs(storagepath);\n",
    "os.chdir(storagepath)\n",
    "for keyframe in os.listdir(path):\n",
    "    frame=setaspectratio(path+\"/\"+keyframe)\n",
    "    rgbframe = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    #frame=cv2.imread(path+\"/\"+keyframe)\n",
    "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    boxes = detector.detect(rgbframe)\n",
    "    # lets's draw boxes, just multiply each predicted [0, 1] relative coordinate to image side in pixels respectively\n",
    "    for box in boxes:\n",
    "        lx = int(round(box[0] * frame.shape[1]))\n",
    "        ly = int(round(box[1] * frame.shape[0]))\n",
    "        rx = int(round(box[2] * frame.shape[1]))\n",
    "        ry = int(round(box[3] * frame.shape[0]))\n",
    "        # x, y, w, h here\n",
    "        #ax.add_patch(Rectangle((lx,ly),rx - lx,ry - ly,linewidth=2,edgecolor='r',facecolor='none'))\n",
    "        frame2 = frame[ly:ry, lx:rx]\n",
    "        rgb = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "        face = cv2.resize(rgb, dim, interpolation=cv2.INTER_LANCZOS4)\n",
    "        cv2.imwrite(\"face\"+str(b)+\".jpg\", face)#Detected face\n",
    "        b=b+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "#Handling Image data Generators\n",
    "test_data_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "newmodel=load_model(\"/content/drive/MyDrive/deepfake/ChkpointXception10weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "extractedfaces=os.listdir(\"/content/drive/MyDrive/sample-faces/\"+vidname)\n",
    "print(extractedfaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "whatdata=[]\n",
    "facepath=\"/content/drive/MyDrive/sample-faces/\"+vidname\n",
    "if os.path.exists(facepath):\n",
    "    for filename in extractedfaces:\n",
    "      if filename.endswith(\"jpg\"):\n",
    "        # Your code comes here such as\n",
    "        whatdata.append(facepath+\"/\"+filename)\n",
    "print(whatdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#creating DataFrame\n",
    "videodf = pd.DataFrame(whatdata, columns=['path'])\n",
    "bs= len(videodf)\n",
    "print(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "videodf['path'] = whatdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "video_imgs = test_data_gen.flow_from_dataframe(dataframe=videodf,x_col='path', target_size=(299,299), class_mode=None,batch_size=bs, shuffle=False)\n",
    "\n",
    "video_prediction = newmodel.predict(video_imgs)\n",
    "\n",
    "predictclass=[]\n",
    "for i in range(0, len(video_prediction)):\n",
    "  predictclass.append(  str(video_prediction[i][:2])  )\n",
    "# for value in predictclass:\n",
    "#  print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "newmodel=load_model(\"/content/drive/MyDrive/deepfake/ChkpointXception10weights.h5\")\n",
    "\n",
    "extractedfaces=os.listdir(\"/content/drive/MyDrive/sample-faces/\"+vidname)\n",
    "print(extractedfaces)\n",
    "\n",
    "whatdata=[]\n",
    "facepath=\"/content/drive/MyDrive/sample-faces/\"+vidname\n",
    "if os.path.exists(facepath):\n",
    "    for filename in extractedfaces:\n",
    "      if filename.endswith(\"jpg\"):\n",
    "        # Your code comes here such as\n",
    "        whatdata.append(facepath+\"/\"+filename)\n",
    "print(whatdata)\n",
    "\n",
    "#creating DataFrame\n",
    "videodf = pd.DataFrame(whatdata, columns=['path'])\n",
    "videodf['path'] = videodf['path'].apply(lambda x: str(x))\n",
    "bs= len(videodf)\n",
    "print(bs)\n",
    "\n",
    "video_imgs = test_data_gen.flow_from_dataframe(dataframe=videodf,x_col='path', target_size=(299,299), class_mode=None,batch_size=bs, shuffle=False)\n",
    "\n",
    "video_prediction = newmodel.predict(video_imgs)\n",
    "\n",
    "predictclass=[]\n",
    "for i in range(0, len(video_prediction)):\n",
    "  predictclass.append(  str(video_prediction[i][:2])  )\n",
    "# for value in predictclass:\n",
    "#  print(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "video_output = np.argmax(video_prediction, axis=1)\n",
    "print(video_output[0:25])\n",
    "avg = video_output.mean()\n",
    "print(avg)\n",
    "if avg >= 0.5 :\n",
    "   predictedclass='real'\n",
    "elif avg <0.5:\n",
    "   predictedclass='fake'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"ACTUAL:\"+actualclass)\n",
    "print(\"PREDICTED :\" +predictedclass)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
